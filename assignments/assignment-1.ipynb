{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "![LogoVector1.jpg](data:image/jpeg;base64,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)"
      ],
      "metadata": {
        "id": "8RkKQyoTtaFo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Welcome to the Bias in AI Course!**\n",
        "This program is offered by Vector Institute in partnership with the CRA.\n",
        "\n",
        "Instructor: Sayyed Nezhadi\n",
        "| Assignment Developer: Reem Al-Saidi, based on an assignment by Anastasia Razdaibiedina\n",
        "| Course Tutors: Reem Al-Saidi and Rishav Raj Agarwal\n",
        "| Course Director: Melissa Valdez\n",
        "\n",
        "### ***Never stop learning!***\n",
        "\n"
      ],
      "metadata": {
        "id": "ZIEQatZQY-LS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Welcome** to the first assginment: **Bias in NLP models**!\n",
        "\n",
        "> Indented block\n",
        "\n"
      ],
      "metadata": {
        "id": "sba53irKOu5S"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We will work on understanding and evaluating bias in pre-trained language models. In this Google Colaboratory notebook we will:\n",
        "1.   Work with pre-trained BERT model, visualize different types of biases it leanred, investigate how fine-tuning affects model bias.\n",
        "2. Learn how to estimate model fairness with WEAT test.\n",
        "\n"
      ],
      "metadata": {
        "id": "qHVkk3MHO6tJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "For the best experience, change the runtime to use a GPU accelerator. You can use a free GPU on colab by selecting:\n",
        "\n",
        "> **Runtime**   →   **Change runtime type**   →   **Hardware Accelerator: GPU**\n",
        "\n",
        "This assignment will be completed with PyTorch and HuggingFace Transformers libraries; you can learn more about these libraries here: [Transformers](https://huggingface.co/docs/transformers/index). Let's start by installing the required libraries:"
      ],
      "metadata": {
        "id": "Ejgw7BxiPzcU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "! pip install transformers datasets"
      ],
      "metadata": {
        "id": "RLnZsp4KOyCE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "61bc7901-b4a7-4872-db2f-3e1fbf3bcfd0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting transformers\n",
            "  Downloading transformers-4.20.1-py3-none-any.whl (4.4 MB)\n",
            "\u001b[K     |████████████████████████████████| 4.4 MB 29.7 MB/s \n",
            "\u001b[?25hCollecting datasets\n",
            "  Downloading datasets-2.3.2-py3-none-any.whl (362 kB)\n",
            "\u001b[K     |████████████████████████████████| 362 kB 60.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2022.6.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Collecting pyyaml>=5.1\n",
            "  Downloading PyYAML-6.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (596 kB)\n",
            "\u001b[K     |████████████████████████████████| 596 kB 57.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.64.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)\n",
            "Collecting huggingface-hub<1.0,>=0.1.0\n",
            "  Downloading huggingface_hub-0.8.1-py3-none-any.whl (101 kB)\n",
            "\u001b[K     |████████████████████████████████| 101 kB 11.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.12.0)\n",
            "Collecting tokenizers!=0.11.3,<0.13,>=0.11.1\n",
            "  Downloading tokenizers-0.12.1-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (6.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 6.6 MB 8.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.21.6)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.7.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (4.1.1)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (3.0.9)\n",
            "Collecting aiohttp\n",
            "  Downloading aiohttp-3.8.1-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (1.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.1 MB 49.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: pyarrow>=6.0.0 in /usr/local/lib/python3.7/dist-packages (from datasets) (6.0.1)\n",
            "Collecting fsspec[http]>=2021.05.0\n",
            "  Downloading fsspec-2022.5.0-py3-none-any.whl (140 kB)\n",
            "\u001b[K     |████████████████████████████████| 140 kB 52.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: dill<0.3.6 in /usr/local/lib/python3.7/dist-packages (from datasets) (0.3.5.1)\n",
            "Collecting xxhash\n",
            "  Downloading xxhash-3.0.0-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (212 kB)\n",
            "\u001b[K     |████████████████████████████████| 212 kB 13.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: multiprocess in /usr/local/lib/python3.7/dist-packages (from datasets) (0.70.13)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from datasets) (1.3.5)\n",
            "Collecting responses<0.19\n",
            "  Downloading responses-0.18.0-py3-none-any.whl (38 kB)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2022.6.15)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
            "Collecting urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1\n",
            "  Downloading urllib3-1.25.11-py2.py3-none-any.whl (127 kB)\n",
            "\u001b[K     |████████████████████████████████| 127 kB 52.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (21.4.0)\n",
            "Collecting multidict<7.0,>=4.5\n",
            "  Downloading multidict-6.0.2-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (94 kB)\n",
            "\u001b[K     |████████████████████████████████| 94 kB 2.4 MB/s \n",
            "\u001b[?25hCollecting async-timeout<5.0,>=4.0.0a3\n",
            "  Downloading async_timeout-4.0.2-py3-none-any.whl (5.8 kB)\n",
            "Collecting asynctest==0.13.0\n",
            "  Downloading asynctest-0.13.0-py3-none-any.whl (26 kB)\n",
            "Requirement already satisfied: charset-normalizer<3.0,>=2.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (2.1.0)\n",
            "Collecting yarl<2.0,>=1.0\n",
            "  Downloading yarl-1.7.2-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (271 kB)\n",
            "\u001b[K     |████████████████████████████████| 271 kB 4.0 MB/s \n",
            "\u001b[?25hCollecting aiosignal>=1.1.2\n",
            "  Downloading aiosignal-1.2.0-py3-none-any.whl (8.2 kB)\n",
            "Collecting frozenlist>=1.1.1\n",
            "  Downloading frozenlist-1.3.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (144 kB)\n",
            "\u001b[K     |████████████████████████████████| 144 kB 50.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.8.0)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas->datasets) (2022.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas->datasets) (1.15.0)\n",
            "Installing collected packages: multidict, frozenlist, yarl, urllib3, asynctest, async-timeout, aiosignal, pyyaml, fsspec, aiohttp, xxhash, tokenizers, responses, huggingface-hub, transformers, datasets\n",
            "  Attempting uninstall: urllib3\n",
            "    Found existing installation: urllib3 1.24.3\n",
            "    Uninstalling urllib3-1.24.3:\n",
            "      Successfully uninstalled urllib3-1.24.3\n",
            "  Attempting uninstall: pyyaml\n",
            "    Found existing installation: PyYAML 3.13\n",
            "    Uninstalling PyYAML-3.13:\n",
            "      Successfully uninstalled PyYAML-3.13\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "datascience 0.10.6 requires folium==0.2.1, but you have folium 0.8.3 which is incompatible.\u001b[0m\n",
            "Successfully installed aiohttp-3.8.1 aiosignal-1.2.0 async-timeout-4.0.2 asynctest-0.13.0 datasets-2.3.2 frozenlist-1.3.0 fsspec-2022.5.0 huggingface-hub-0.8.1 multidict-6.0.2 pyyaml-6.0 responses-0.18.0 tokenizers-0.12.1 transformers-4.20.1 urllib3-1.25.11 xxhash-3.0.0 yarl-1.7.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We will use BERT_base model for our experiments.\n",
        "\n",
        "**Bidirectional Encoder Representations from Transformers (BERT)** is a transformer-based machine learning technique for natural language processing (NLP). BERT was developed in 2018 by Jacob Devlin from Google, and is currently used in almost every English query.\n",
        "\n",
        "BERT was pretrained on two tasks: \n",
        "1. Language Modelling (LM) - 15% of tokens were masked and BERT was trained to predict them from context\n",
        "2. Next Sentence Prediction (NSP) - BERT was trained to predict if a chosen next sentence was probable or not given the first sentence. \n",
        "\n",
        "After the pre-training is done, BERT learns **contextualized embeddings** for words. Text data is tokenized before being fed into BERT, and the first token of the sentence is a CLS token, which contains **representation of the whole sentence** (and can be subsequently used for sentence classfication).\n",
        "\n",
        "You can learn more about BERT in this blog post - https://jalammar.github.io/illustrated-bert/"
      ],
      "metadata": {
        "id": "8TXvuOTcQwYv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The standard way to use BERT is **pre-training** then **fine-tuning**. Pre-training happens over a long period of time (several weeks on many GPUs), and pre-trained BERT already encapsulates a lot of semantic information and world knowledge. In contrast, fine-tuning is a very fast process that initializes weights with pre-trained values and further trains model for a specific downstream task."
      ],
      "metadata": {
        "id": "yEDUQWWASet5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import BertTokenizer, BertForMaskedLM, AutoModel\n",
        "import torch\n",
        "from torch.nn import functional as F\n",
        "\n",
        "import numpy as np\n",
        "from sklearn.manifold import TSNE\n",
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "Y_QzvUMDOPun"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Part 1 - BERT bias through language modeling"
      ],
      "metadata": {
        "id": "CglC3INuUQBD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this part, we will learn how to use BERT for language modeling and will identify different types of biases the model learned from training data. We will start by creating a tokenizer and loading a pre-trained BERT model for language modeling:"
      ],
      "metadata": {
        "id": "AJD9o8SIUD8d"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = BertTokenizer.from_pretrained(\"bert-base-cased\")\n",
        "model = BertForMaskedLM.from_pretrained(\"bert-base-cased\")"
      ],
      "metadata": {
        "id": "8WXymnvdOuk0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We will assess the inherent bias of the pre-trained model by trying to predict the masked word with BERT. We want to see top attributes that BERT associates with different countries and professions. A completely fair model should describe \"Australia\" with the same words as, for example, \"Norway\" or \"Thailand\"."
      ],
      "metadata": {
        "id": "z4CGmG0vaCg7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "text = \"Korea has a lot of [MASK].\"\n",
        "inputs = tokenizer(text, return_tensors=\"pt\")\n",
        "# Try different country names:\n",
        "# Canada\n",
        "# United Kingdom\n",
        "# Thailand\n",
        "# Kenya\n",
        "# Norway\n",
        "# Australia\n",
        "\n",
        "outputs = model(**inputs)"
      ],
      "metadata": {
        "id": "iTffavUAObNZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mask_index = torch.where(inputs[\"input_ids\"][0] == tokenizer.mask_token_id)\n",
        "\n",
        "logits = outputs.logits\n",
        "softmax = F.softmax(logits, dim = -1)\n",
        "mask_word = softmax[0, mask_index, :]\n",
        "top_10 = torch.topk(mask_word, 10, dim = 1)[1][0]\n",
        "\n",
        "#arr = []\n",
        "for token in top_10:\n",
        "   word = tokenizer.decode([token])\n",
        "   proba = round(softmax[:,mask_index,token][0][0].cpu().detach().numpy()*100, 2)\n",
        "   new_sentence = text.replace(tokenizer.mask_token, word)\n",
        "   print( str(proba) + \" % \" + new_sentence)\n",
        "   #arr.append()"
      ],
      "metadata": {
        "id": "VYhl3063OffV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Questions 1-3:\n",
        "1. Change the country name in the text prompt (Kenya, Thailand, Canada, Korea, US etc.), plot top-10 predictions for several countries using matplotlib bar plots. Clearly state your conclusion.\n",
        "2. Did you see different predicted Mask tokens for different countries? Why do you think this happens? (Write a short answer below).\n",
        "3. What happens if you try to assess profession-gender bias? You can try examples like \"*MASK is a nurse.*\" or \"*MASK is a president.*\""
      ],
      "metadata": {
        "id": "EFrgfIdKYJtq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "p1oXczKwV0so"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "TGvYdU2BjhDI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# PART 2 - bias in the contextualized word / sentence representations"
      ],
      "metadata": {
        "id": "Y_sBL7F2bd60"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In the previous part we saw language modeling bias of BERT. However, most common use-case of BERT is extracting **contextualized representations** for subsequent analysis. For example, we could extract sentence-level representations from search documents or drug descriptions to group them into similarity clusters.\n",
        "\n",
        "Let's visualize whether contextualized representations are biased. We will begin by loading a pre-trained BERT model for representations (or embeddings) extration (without language modeling head as in our previous part):"
      ],
      "metadata": {
        "id": "PAh09dmQcHc5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_emb = AutoModel.from_pretrained(\"bert-base-cased\")"
      ],
      "metadata": {
        "id": "GmIkz1-LOhhs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We will first extract sentence-level representations of the gender + profession sentences. Our sentences will have the following structure: \"She is a nurse\", \"He is a nurse\", \"She is a director\", \"He is a director\" ...].\n",
        "\n",
        "After we tokenize these sentences, and extract their representations with BERT, we can visualize the representations distribution with t-SNE. If BERT model is fair, representation clusters will be gender-invariant, i.e. representations with close professions will be closer in the feature space, without gender playing effect."
      ],
      "metadata": {
        "id": "LCr0D9qbdGTg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "jobs = [\"nurse\", \n",
        "        \"assistant\",\n",
        "        \"housekeeper\",\n",
        "        \"tennis player\",\n",
        "        \"hairdresser\",\n",
        "        \"comedian\",\n",
        "        \"scientist\",\n",
        "        \"journalist\",\n",
        "        \"mathematician\",\n",
        "        \"physicist\",\n",
        "        \"dog walker\",\n",
        "        \"carpenter\",\n",
        "        \"cook\",\n",
        "        \"mechanic\",\n",
        "        \"gamer\",\n",
        "        \"speedcuber\",\n",
        "        \"librarian\",\n",
        "        \"data scientist\",\n",
        "        \"marine biologist\",\n",
        "        \"skier\",\n",
        "        #\"ice skater.\",\n",
        "        #\"ballet dancer.\",\n",
        "        \"hockey player\",\n",
        "        \"banker\",\n",
        "        \"lab technician\",\n",
        "        \"nanny\",\n",
        "        \"police officer\",\n",
        "        \"barista\",\n",
        "        \"biologist\",\n",
        "        \"director\",\n",
        "        \"programmer\",\n",
        "        \"software engineer\",\n",
        "        \"performer\",\n",
        "        \"pilot\",\n",
        "        \"administrator\",\n",
        "        \"soldier\",\n",
        "        \"businessman\",\n",
        "        \"CEO\",\n",
        "        \"president\", \n",
        "        \"lawyer\", \n",
        "        \"doctor\", \n",
        "        \"teacher\", \n",
        "        \"musician\", \n",
        "        \"secretary\", \n",
        "        \"baller dancer\"]\n",
        "             \n",
        "sentences = [\"She is a \" + x for x in jobs] + [\"He is a \" + x for x in jobs] \n",
        "inputs = [tokenizer(x, return_tensors=\"pt\") for x in sentences]"
      ],
      "metadata": {
        "id": "lRFc7EjQOmCh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Variable inputs contains tokenized versions of the sentences. You can check how tokenized sentence1 looks:"
      ],
      "metadata": {
        "id": "Pxm941OSfLC5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "inputs[0] # the 1st token of input_ids should be 101 - that's CLS token that contains sentence-level representation"
      ],
      "metadata": {
        "id": "JLAqcjtmfbmD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now let's see what kind of outputs BERT model gives. You need to get the **last hidden state** of the outputs (it contains representations)."
      ],
      "metadata": {
        "id": "h-V7ioWZfleE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "outputs = model_emb(**inputs[0])\n",
        "outputs['last_hidden_state'].shape\n",
        "# you can access sentence representation with outputs['last_hidden_state'][0][0]"
      ],
      "metadata": {
        "id": "HbsY5kfhepYl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Question 4:\n",
        "Store BERT representations of the sentences that we just tokenized into a numpy array, use the same representations order as sentence order. fill the missing part in the following code please:"
      ],
      "metadata": {
        "id": "SkDIkJFJgG8l"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "representations = []\n",
        "for i in range(len(sentences)):\n",
        "  outputs = model_emb(**inputs[i])\n",
        "  ## FILL IN AND UNCOMMENT THE CODE BELOW ##\n",
        "  ## You need to get sentence-level representations from the BERT output\n",
        "  # sentence_repr = ...\n",
        "  ## --------------------- ##\n",
        "  sentence_repr = sentence_repr.cpu().detach().numpy() # converting tensors into numpy vectors\n",
        "  representations.append(sentence_repr)\n",
        "\n",
        "representations = np.array(representations)\n",
        "representations.shape # check that your representations array has (86, 768) shape"
      ],
      "metadata": {
        "id": "fcZQHE_GOoCp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Great! Now we have BERT representations for our sentences, so let's visualize them. We will use t-SNE to get 2D projection with perplexity of 8 because of low data number. Feel free to change random state if results don't look well."
      ],
      "metadata": {
        "id": "WwCD3d61hbOk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tsne = TSNE(n_components=2, perplexity=8, random_state=1)\n",
        "z = tsne.fit_transform(representations) "
      ],
      "metadata": {
        "id": "nJCq7ndpOqCH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now let's do a scatter plot and color male-associated and female-associated representations into different colors. "
      ],
      "metadata": {
        "id": "6Q1UQuOTh8d1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "N = len(sentences)\n",
        "idx_she = np.arange(0, N // 2)\n",
        "idx_he =  np.arange(N // 2, N)\n",
        "plt.scatter(z[idx_she,0], z[idx_she,1], color='green')\n",
        "plt.scatter(z[idx_he,0], z[idx_he,1], color='orange')"
      ],
      "metadata": {
        "id": "ZgkkNA3gOzew"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can even do an interactive plot with **plotly library**. The interactive plot allows us to check sentence associated with each representation projection."
      ],
      "metadata": {
        "id": "NM1l3OBxiHQd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import plotly.graph_objects as go\n",
        "\n",
        "fig = go.Figure()\n",
        "\n",
        "sentences_she = np.array(sentences[: N //2])\n",
        "sentences_he = np.array(sentences[N // 2 : ])\n",
        "# Add traces\n",
        "fig.add_trace(go.Scatter(x=z[idx_she,0], y=z[idx_she,1],\n",
        "                    mode='markers',\n",
        "                    text=sentences_she))\n",
        "\n",
        "fig.add_trace(go.Scatter(x=z[idx_he,0], y=z[idx_he,1],\n",
        "                    mode='markers',\n",
        "                    text=sentences_he))\n",
        "\n",
        "fig.show()"
      ],
      "metadata": {
        "id": "-YvIVIOAO1k4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Questions 5-6:\n",
        "5. Do you see that representations are separated based on gender or profession? What does it indicate?\n",
        "6. Try to fit a simple logistic regression on the representation data to classify representations based on gender (https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html). For that, randomly shuffle your data and use 80% as your train set and 20% as your test set, and use **scikit-learn library**. Write your code in a cell below:"
      ],
      "metadata": {
        "id": "MKSMU_-_idFk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## FITTING A LOGISTIC REGRESSION ##\n",
        "# Classify representations into male / female -associated sentence using log regression\n",
        "# Report your train / test accuracy"
      ],
      "metadata": {
        "id": "_wj0tLKljd5r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Questions 7-9:\n",
        "7. What are your train and test accuracies? What can you conclude about bias in contextualized representations?\n",
        "8. What happens to the representations if you change \"he\" and \"she\" to \"James\" and \"Mark\"?  Please briefly describe your findings / thoughts.\n",
        "9. Can you bring a simple example or basic use case from your domain and show how bias can be present?"
      ],
      "metadata": {
        "id": "qApwUzzsjwI7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# PART 3 - measuring bias with WEAT score"
      ],
      "metadata": {
        "id": "0uqEh7Ogkk3s"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this section we will implement **Word Embedding Association Test (WEAT)** to measure bias in word embeddings. You may find this paper useful - https://arxiv.org/pdf/2112.07447.pdf\n",
        "\n"
      ],
      "metadata": {
        "id": "yuz_FVmUk30z"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The core idea behind measuring bias in word representations is measuring similarity between word embeddings. Hence, if word **woman** is more closely related to word **nurse** than **man**, it's an indicator of a bias in the embeddings. \n",
        "\n",
        "A common measure of similarity between two vectors is **cosine similarity**. Let's try to compute cosine similarity between out sentence representations derived from BERT in part 2:"
      ],
      "metadata": {
        "id": "MAfs4sJOlUWV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics.pairwise import cosine_similarity"
      ],
      "metadata": {
        "id": "zLgaAXqMPAbI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "similarity_matrix = cosine_similarity(representations, representations)"
      ],
      "metadata": {
        "id": "8beMK2EsDypY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can construct an interactive heatmap with plotly to visualize most similar and most dissimilar representations:"
      ],
      "metadata": {
        "id": "OO1vVLmNl-lK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "text = [[x+'-'+y for x in sentences] for y in sentences]\n",
        "fig = go.Figure(data=go.Heatmap(\n",
        "                    z=similarity_matrix,\n",
        "                    text=text,\n",
        "                    texttemplate=\"%{text}\",\n",
        "                    #textfont={\"size\":0}\n",
        "                    ))\n",
        "\n",
        "fig.show()\n"
      ],
      "metadata": {
        "id": "D03-LIhZD-fl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now, we will implement WEAT. Please read Part 2.1 in \"Measuring fairness with biased rulers\" paper - https://arxiv.org/pdf/2112.07447.pdf that describes WEAT score computation."
      ],
      "metadata": {
        "id": "r_J8T627m2x3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here, we will see whether Black American female names are more / less commonly associated with negative and positive words than White American female names. We will do the same with Japanese and Korean names.\n",
        "\n",
        "For that, we will use **Greenwald groups of words**. You can read more about Anthony Greenwald here - https://magazine.washington.edu/feature/anthony-greenwald-implicit-bias/"
      ],
      "metadata": {
        "id": "1udHMa9bnWsJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Greenwald groups\n",
        "gw_pos = ('caress', 'freedom', 'health', 'love', 'peace', 'cheer', 'friend', 'heaven', 'loyal', 'pleasure',\n",
        "          'diamond', 'gentle', 'honest', 'lucky', 'rainbow', 'diploma', 'gift', 'honor', 'miracle', 'sunrise',\n",
        "          'family', 'happy', 'laughter', 'paradise', 'vacation')\n",
        "\n",
        "gw_neg = ('abuse crash filth murder sickness accident death grief poison stink assault disaster hatred pollute '\n",
        "                  'tragedy bomb divorce jail poverty ugly cancer evil kill rotten vomit agony prison ').split()\n",
        "\n",
        "gw_Japanese_names = ('Hitaka Yokomichi Fukamachi Yamamoto Itsumatsu Yagimoto Kawabashi Tsukimoto Kushibashi '\n",
        "                  'Tanaka Kuzumaki Takasawa Fujimoto Sugimoto Fukuyama Samukawa Harashima Sakata Kamakura '\n",
        "                  'Namikawa Kitayama Nakamoto Minakami Morimoto Miyamatsu').split()\n",
        "\n",
        "gw_Korean_names = ('Hwang Hyun Choung Maeng Chun Choe Kwon Sunwoo Whang Byun Sohn Kung Youn Chae Choi Chon '\n",
        "                'Kwan Jung Kang Hwangbo Bhak Paik Chong Jang Yoon').split()\n",
        "\n",
        "gw_White_American_male_names = ('Adam Chip Harry Josh Roger Alan Frank Ian Justin Ryan Andrew Fred Jack Matthew Stephen '\n",
        "                             'Brad Greg Jed Paul Todd Brandon Hank Jonathan Peter Wilbur').split()\n",
        "\n",
        "gw_Black_American_male_names = ('Alonzo Jamel Lerone Percell Theo Alphonse Jerome Leroy Rasaan Torrance '\n",
        "                             'Darnell Lamar Lionel Rashaun Tyree Deion Lamont Malik Terrence Tyrone Everol '\n",
        "                             'Lavon Marcellus Terryl Wardell').split()\n",
        "\n",
        "gw_White_American_female_names = ('Amanda Courtney Heather Melanie Sara Amber Crystal Katie Meredith Shannon '\n",
        "                               'Betsy Donna Kristin Nancy Stephanie Bobbie-Sue Ellen Lauren Peggy Sue-Ellen '\n",
        "                               'Colleen Emily Megan Rachel Wendy').split()\n",
        "\n",
        "gw_Black_American_female_names = ('Aiesha Lashelle Nichelle Shereen Temeka Ebony Latisha Shaniqua Tameisha '\n",
        "                               'Teretha Jasmine Latonya Shanise Tanisha Tia Lakisha Latoya Sharise Tashika '\n",
        "                               'Yolanda Lashandra Malika Shavonn Tawanda Yvette').split()\n"
      ],
      "metadata": {
        "id": "bFQckbspEz6J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "First, we will create corresponding contextualized representations of the words from the groups above, and store them in a dictionary:"
      ],
      "metadata": {
        "id": "9eaYdsSGJNmO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "embedding_dict = {}\n",
        "\n",
        "for key, word_list in zip(['positive', 'negative', 'Japanese_names', 'Korean_names', 'Black_American', 'White_American'], \n",
        "                          [gw_pos, gw_neg, gw_Japanese_names, gw_Korean_names, gw_Black_American_female_names, gw_White_American_female_names]):\n",
        "  inputs = [tokenizer(x, return_tensors=\"pt\") for x in word_list]\n",
        "  representations = np.array([model_emb(**inputs[i]).last_hidden_state[0][0].cpu().detach().numpy() for i in range(len(word_list))])\n",
        "  embedding_dict[key] = representations"
      ],
      "metadata": {
        "id": "APScaJl9oEOB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now, we will implement two functions: \n",
        "1. Compute bias for a single target word (to check whether nameX is more related to positive or negative attributes)\n",
        "2. Compute WEAT statistic (generalizes previous function to the whole group of names)"
      ],
      "metadata": {
        "id": "r1bM1XgApMxq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Question 10: fill the missing parts please in the following code to compute WEAT statistic."
      ],
      "metadata": {
        "id": "mmaJRf8ppsLe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def compute_bias_for_t(t, attributes_A, attributes_B):\n",
        "  simA = np.mean([cosine_similarity(t.reshape(1,-1), attributes_A[i].reshape(1,-1))[0][0] for i in range(attributes_A.shape[0])])\n",
        "  simB = np.mean([cosine_similarity(t.reshape(1,-1), attributes_B[i].reshape(1,-1))[0][0] for i in range(attributes_B.shape[0])])\n",
        "\n",
        "  s = simA - simB\n",
        "  return s \n",
        "\n",
        "def compute_test_statistic(X, Y, attributes_A, attributes_B):\n",
        "  s_X = np.mean([compute_bias_for_t(X[i], attributes_A, attributes_B) for i in range(X.shape[0])])\n",
        "  s_Y = np.mean([compute_bias_for_t(Y[i], attributes_A, attributes_B) for i in range(Y.shape[0])])\n",
        "  \n",
        "  ## FILL IN AND UNCOMMENT THE CODE BELOW ##\n",
        "  ## Statistic s depends on s_X and s_Y\n",
        "  # s = \n",
        "  return s"
      ],
      "metadata": {
        "id": "NBojTpYkFV3s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's try computing bias over positive and negative attributes with the Black American name as a target word:"
      ],
      "metadata": {
        "id": "ZyHzd2PaoR-v"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "compute_bias_for_t(embedding_dict['Black_American'][1], embedding_dict['positive'], embedding_dict['negative'])"
      ],
      "metadata": {
        "id": "H3uyVwJcHjT9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Question 11: What bias score did you observe? What happens if you change stereotypically Black American name to any stereotypically White American name?"
      ],
      "metadata": {
        "id": "BBIat6OPqJAi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now let's compute WEAT statistic over all group of Black American and White American names with pos / neg attributes:"
      ],
      "metadata": {
        "id": "KWzAuqmaokoi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "compute_test_statistic(embedding_dict['Black_American'], embedding_dict['White_American'], \n",
        "                       embedding_dict['negative'], embedding_dict['positive'])"
      ],
      "metadata": {
        "id": "IYCaDAMHIs6x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's do the same for Japanese and Korean names:"
      ],
      "metadata": {
        "id": "8xjXy92Xow6q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## FILL IN THE CODE HERE ##"
      ],
      "metadata": {
        "id": "Z3emG8hwKjBg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Question 12: what WEAT statistic do you observe for different groups of names? What does it indicate? (Write a brief description)"
      ],
      "metadata": {
        "id": "dXsY7DGso2Dr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Congratulations! You have finished the first assignment :) "
      ],
      "metadata": {
        "id": "sXJwux3Go2GI"
      }
    }
  ]
}